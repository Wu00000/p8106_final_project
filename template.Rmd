---
title: "Simple document"
output: pdf_document
---

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(skimr)
library(caret)
library(visdat)
library(corrplot)
library(AppliedPredictiveModeling)
library(pROC)
library(rpart.plot)
library(vip)
library(ranger)
library(tidytext)
library(pdp)
library(lime)


ctrl <- trainControl(method = "cv",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)

knitr::opts_chunk$set(
  fig.width = 6,
  out.width = "80%",
  fig.align = "center"
  )

```


## Data pre-process
```{r}
# Import data
dat_raw <- read.csv("airline.csv")

# find unique value of each column
sapply(dat_raw, function(x) length(unique(x)))

# Check missing value
sapply(dat_raw, function(x) sum(is.na(x)))

# Have a glance of the data
skimr::skim_without_charts(dat_raw)

# data clean
dat <- dat_raw %>% 
  janitor::clean_names() %>% 
  select(-1) %>% 
  mutate(satisfaction = recode(satisfaction,
                          "satisfied" = "yes",
                          "neutral or dissatisfied" = "no")) %>% 
  filter_at(vars(7:20), all_vars(. > 0.5))

# deal with missing values
deal_mis <- dat[, 21:22]
bagImp = preProcess(deal_mis, method = "bagImpute")
dat = predict(bagImp, dat)
vis_miss(deal_mis)

# sample data
set.seed(1234)
dat <- dat[sample(1:nrow(dat), 2000, replace = FALSE), ]
vis_miss(dat) ## check

# --- Split data ---
set.seed(1234)
trRow <- createDataPartition(dat$satisfaction, p = 0.8, list = F)

# Train data
train <- dat[trRow, ]
x_train <- model.matrix(satisfaction ~., train)[,-1]
y_train <- train$satisfaction

# Test data
test <- dat[-trRow, ]
x_test <- model.matrix(satisfaction ~., test)[,-1]
y_test <- test$satisfaction
```

## EDA
```{r}
# Correlation plot
corrplot(cor(x_train),
         method = "circle", 
         type = "upper",
         tl.col = "black",
         tl.cex = 0.4)
```

```{r, fig.width=10, fig.height=6}
# Barplot matrix for categorical variables
train %>% 
  select(1:2, 4:5, 23) %>% 
  pivot_longer(-5,
               names_to = "variable",
               values_to = "value") %>% 
  group_by(variable, value, satisfaction) %>% 
  summarize(num = n()) %>% 
  mutate(indicator = case_when(value == "Eco" ~ 3,
                               value == "Eco Plus" ~ 2,
                               value == "Business" ~ 1,
                               TRUE ~ 0)) %>% 
  ggplot(aes(x = reorder_within(value, indicator, variable),
             y = num, fill = satisfaction)) +
  geom_col(position = "dodge") + 
  xlab("Barplot matrix for categorical variables") +
  coord_flip() +
  scale_x_reordered() +
  facet_wrap(~ variable, scales = "free") + theme_bw()
```

```{r}
# Density plot matrix
theme1 <- transparentTheme(trans = .5)
trellis.par.set(theme1)

plt_feature <- 
  featurePlot(x = x_train[ , c(-1, -2, -4, -5, -6)],
              y = as.factor(y_train),
              plot = "density",
              scales = list(x = list(relation = "free"),
                            y = list(relation = "free")),
              pch = "|", auto.key = list(columns = 2))
update(plt_feature, main = "Density Plot Matrix")
```

# Model fitting
## Logistic regression
```{r}
set.seed(1234)
model.glm <- train(x = x_train,
                   y = y_train,
                   method = "glm",
                   metric = "ROC",
                   trControl = ctrl)

# Test AUC and Misclassification error rate
pred_glm_auc <- predict(model.glm, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_glm_auc)$auc[1]

# Confusion matrix
pred_glm <- predict(model.glm, newdata = x_test)
confusionMatrix(data = as.factor(pred_glm),
                reference = as.factor(y_test))
```


## MARS
```{r message = FALSE, warning = FALSE}
set.seed(1234)
model.mars <- train(x = x_train,
                    y = y_train,
                    method = "earth",
                    tuneGrid = expand.grid(degree = 1:4,
                                           nprune = 5:30),
                    metric = "ROC",
                    trControl = ctrl)

model.mars$bestTune
ggplot(model.mars, highlight = T) + 
  theme_bw()

## test auc and misclassification error rate
pred_mars_auc <- predict(model.mars, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_mars_auc)$auc[1]

pred_mars <- predict(model.mars, newdata = x_test)
pred.miserror_mars <- 1 - mean(pred_mars == y_test)
pred.miserror_mars


confusionMatrix(data = as.factor(pred_mars),
                reference = as.factor(y_test))

# check
coef(model.mars$finalModel)
```


## LDA
```{r}
set.seed(1234)
model.lda <- train(x = x_train,
                   y = y_train,
                   method = "lda",
                   metric = "ROC",
                   trControl = ctrl)

## test auc and misclassification error rate
pred_lda_auc <- predict(model.lda, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_lda_auc)$auc[1]

pred_lda <- predict(model.lda, newdata = x_test)
pred.miserror_lda <- 1 - mean(pred_lda == y_test)
pred.miserror_lda

confusionMatrix(data = as.factor(pred_lda),
                reference = as.factor(y_test))

# check
library(MASS)
lda.fit <- lda(satisfaction ~., data = train)
plot(lda.fit)
```

## Classification Tree

```{r message=FALSE, warning=FALSE}
set.seed(1234)
model.tree <- train(x_train,
                    y_train,
                    method = "rpart",
                    tuneGrid = data.frame(cp = exp(seq(-10, -6, length = 30))),
                    trControl = ctrl,
                    metric = "ROC")

model.tree$bestTune
ggplot(model.tree, highlight = TRUE) +
  scale_x_continuous(trans = scales::log_trans(),
                     breaks = scales::log_breaks()) + 
  theme_bw()

rpart.plot(model.tree$finalModel)

## test auc and misclassification error rate
pred_tree_auc <- predict(model.tree, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_tree_auc)$auc[1]

pred_tree <- predict(model.tree, newdata = x_test)
pred.miserror_tree <- 1 - mean(pred_tree == y_test)
pred.miserror_tree

confusionMatrix(data = as.factor(pred_tree),
                reference = as.factor(y_test))
```

## Ramdom forests

```{r}
set.seed(1234)
model.rf = train(x_train,
                 y_train,
                 method = "ranger",
                 tuneGrid = expand.grid(mtry = 3:14,
                                        splitrule = "gini",
                                        min.node.size = seq(4, 14, by = 2)),
                 metric = "ROC",
                 trControl = ctrl)

model.rf$bestTune
ggplot(model.rf, highlight = T) + 
  theme_bw()

## test auc and misclassification error rate
pred_rf_auc <- predict(model.rf, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_rf_auc)$auc[1]

pred_rf <- predict(model.rf, newdata = x_test)
pred.miserror_rf <- 1 - mean(pred_rf == y_test)
pred.miserror_rf

confusionMatrix(data = as.factor(pred_rf),
                reference = as.factor(y_test))
```


## Fit a support vector classifier (linear kernel)
```{r message=FALSE, warning=FALSE}
set.seed(1234)
model.svml = train(x_train,
                   y_train,
                   method = "svmLinear",
                   metric = "ROC",
                   tuneGrid = data.frame(C = exp(seq(-5, 1, length = 30))),
                   trControl = ctrl)

ggplot(model.svml, highlight = TRUE) +
  scale_x_continuous(trans = scales::log_trans(),
                     breaks = scales::log_breaks()) + 
  theme_bw()

## test auc and misclassification error rate
pred_svml_auc <- predict(model.svml, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_svml_auc)$auc[1]

pred_svml <- predict(model.svml, newdata = x_test)
pred.miserror_svml <- 1 - mean(pred_svml == y_test)
pred.miserror_svml

confusionMatrix(data = as.factor(pred_svml),
                reference = as.factor(y_test))
```

## Fit a support vector machine with a radial kernel

```{r}
set.seed(1234)
model.svmr = train(x_train,
                 y_train,
                 method = "svmRadialSigma",
                 metric = "ROC",
                 tuneGrid = expand.grid(C = exp(seq(-1, 3, length = 20)),
                                       sigma = exp(seq(-7, -3, length = 20))),
                 trControl = ctrl)

model.svmr$bestTune
myCol<- rainbow(20)
myPar <- list(superpose.symbol = list(col = myCol),
superpose.line = list(col = myCol))
plot(model.svmr, highlight = TRUE, par.settings = myPar)

## test auc and misclassification error rate
pred_svmr_auc <- predict(model.svmr, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_svmr_auc)$auc[1]

pred_svmr <- predict(model.svmr, newdata = x_test)
pred.miserror_svmr <- 1 - mean(pred_svmr == y_test)
pred.miserror_svmr

confusionMatrix(data = as.factor(pred_svmr),
                reference = as.factor(y_test))
```

## Resample

```{r}
resamp <- resamples(list(glm = model.glm, mars = model.mars,
                         lda = model.lda, cla_tree = model.tree,
                         rf = model.rf, svml = model.svml,
                         svmr = model.svmr))

bwplot(resamp)
```

### Select the rf model and interpret

```{r, fig.width=4}
## importance variable
set.seed(1234)
rf2.final.per <- ranger(factor(satisfaction) ~ .,
                        data = train,
                        mtry = model.rf$bestTune[[1]],
                        min.node.size = model.rf$bestTune[[3]],
                        splitrule = "gini",
                        importance = "permutation",
                        scale.permutation.importance = TRUE)

barplot(sort(ranger::importance(rf2.final.per), decreasing = FALSE),
        las = 2,
        horiz = TRUE,
        cex.names = 0.4,
        col = colorRampPalette(colors = c("cyan", "blue"))(8))
```

```{r}
pdp1.rf <- model.rf %>% 
  partial(pred.var = c("inflight_wifi_service")) %>% 
  autoplot(train = train) + theme_bw()

pdp2.rf <- model.rf %>% 
  partial(pred.var = c("inflight_entertainment", "online_boarding"), chull = TRUE) %>% 
  autoplot(train = train) + theme_bw()

grid.arrange(pdp1.rf, pdp2.rf, nrow = 1)
```

```{r}
ice.rf <- model.rf %>% 
  partial(pred.var = "cleanliness",
           grid.resolution = 100,
           ice = TRUE) %>% 
  autoplot(train = dat, alpha = .1,
           center = TRUE) + theme_bw()

ice.rf
```

```{r}
## lime
# explain.rf <- lime(data.frame(x_train), model.rf)

# new_obs = x_test[1:10,]
# explana.obs = explain(new_obs,
#                       explain.rf,
#                       n_features = 5)
# 
# plot_features(explana.obs)
```


