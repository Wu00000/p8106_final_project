---
title: "Simple document"
output: pdf_document
---

```{r setup}
library(tidyverse)
library(readxl)
library(caret)
library(corrplot)
library(AppliedPredictiveModeling)
library(pROC)
library(rpart.plot)


ctrl <- trainControl(method = "cv",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```


## Data pre-process
```{r}
# Import data
dat_raw <- read_csv("./dat1.csv") 

# Check missing value
sapply(dat_raw, function(x) sum(is.na(x)))

dat <- dat_raw %>% 
  janitor::clean_names() %>% 
  select(-1, -2) %>% 
  mutate(satisfaction = recode(satisfaction,
                          "satisfied" = "yes",
                          "neutral or dissatisfied" = "no"),
         arrival_delay_in_minutes = replace(., is.na(.), NA))

set.seed(1234)
dat <- dat[sample(1:nrow(dat), 2000, replace = FALSE), ]

# --- Split data ---
set.seed(1234)
trRow <- createDataPartition(dat$satisfaction, p = 0.8, list = F)

# Train data
train <- dat[trRow, ]
x_train <- model.matrix(satisfaction ~., train)[,-1]
y_train <- train$satisfaction

# Test data
test <- dat[-trRow, ]
x_test <- model.matrix(satisfaction ~., test)[,-1]
y_test <- test$satisfaction
```


## EDA
```{r, fig.height = 6, fig.width = 6}
# Correlation plot
corrplot(cor(x_train),
         method = "circle", 
         type = "upper", 
         tl.col = "black",
         tl.cex = 1.2,
         tl.srt = 50)
```

```{r, fig.height=4, fig.width=4}
# Barplot matrix for categorical variables
nba_train %>% 
  select(2, 3, 5:9, 12) %>% 
  pivot_longer(-1,
               names_to = "Variable",
               values_to = "Value") %>% 
  group_by(Variable, Value, Attrition) %>% 
  summarize(num = n()) %>% 
  ungroup() %>% 
  group_by(Variable, Attrition) %>% 
  mutate(percent = num / sum(num)) %>% 
  ggplot(aes(x = Value, y = percent, fill = Attrition)) +
  geom_col(position = "dodge") + 
  coord_flip() +
  facet_wrap(~ Variable, scales = "free") + theme_bw()

# Density plot matrix
theme1 <- transparentTheme(trans = .5)
trellis.par.set(theme1)

plt_feature <- 
  featurePlot(x = x_train[, c(1, 4, 22, 23, 27)],
              y = as.factor(y_train),
              plot = "density",
              scales = list(x = list(relation = "free"),
                            y = list(relation = "free")),
              pch = "|", auto.key = list(columns = 2))
update(plt_feature, main = "Density Plot Matrix")
```


# Model fitting
## Logistic regression
```{r}
set.seed(1234)
model.glm <- train(x = x_train,
                   y = y_train,
                   method = "glm",
                   metric = "ROC",
                   trControl = ctrl)


# Test AUC and Misclassification error rate
pred_glm_auc <- predict(model.glm, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_glm_auc)$auc[1]

# Confusion matrix
pred_glm <- predict(model.glm, newdata = x_test)
confusionMatrix(data = as.factor(pred_glm),
                reference = as.factor(y_test))
```


## MARS
```{r message = FALSE, warning = FALSE}
set.seed(1234)
model.mars <- train(x = x_train,
                    y = y_train,
                    method = "earth",
                    tuneGrid = expand.grid(degree = 1:3,
                                           nprune = 5:20),
                    metric = "ROC",
                    trControl = ctrl)

model.mars$bestTune
ggplot(model.mars, highlight = T) + 
  theme_bw()

## test auc and misclassification error rate
pred_mars_auc <- predict(model.mars, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_mars_auc)$auc[1]

pred_mars <- predict(model.mars, newdata = x_test)
pred.miserror_mars <- 1 - mean(pred_mars == y_test)
pred.miserror_mars

confusionMatrix(data = as.factor(pred_mars),
                reference = as.factor(y_test))
```

## LDA

```{r}
set.seed(2022)
model.lda <- train(x = x_train,
                   y = y_train,
                   method = "lda",
                   metric = "ROC",
                   trControl = ctrl1)

## test auc and misclassification error rate
pred_lda_auc <- predict(model.lda, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_lda_auc)$auc[1]

pred_lda <- predict(model.lda, newdata = x_test)
pred.miserror_lda <- 1 - mean(pred_lda == y_test)
pred.miserror_lda
```

## Classification Tree

```{r message=FALSE, warning=FALSE}
set.seed(2022)
model.tree <- train(x_train,
                    y_train,
                    method = "rpart",
                    tuneGrid = data.frame(cp = exp(seq(-7, -5, length = 30))),
                    trControl = ctrl1,
                    metric = "ROC")

ggplot(model.tree, highlight = TRUE) +
  scale_x_continuous(trans = scales::log_trans(),
                     breaks = scales::log_breaks()) + 
  theme_bw()

rpart.plot(model.tree$finalModel)

## test auc and misclassification error rate
pred_tree_auc <- predict(model.tree, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_tree_auc)$auc[1]

pred_tree <- predict(model.tree, newdata = x_test)
pred.miserror_tree <- 1 - mean(pred_tree == y_test)
pred.miserror_tree
```

## Ramdom forests

```{r}
set.seed(2022)
model.rf = train(x_train,
                 y_train,
                 method = "ranger",
                 tuneGrid = expand.grid(mtry = 1:8,
                                        splitrule = "gini",
                                        min.node.size = seq(4, 16, by = 2)),
                 metric = "ROC",
                 trControl = ctrl1)

model.rf$bestTune
ggplot(model.rf, highlight = T) + 
  theme_bw()

## test auc and misclassification error rate
pred_rf_auc <- predict(model.rf, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_rf_auc)$auc[1]

pred_rf <- predict(model.rf, newdata = x_test)
pred.miserror_rf <- 1 - mean(pred_rf == y_test)
pred.miserror_rf
```

## Adaboost

```{r}
set.seed(2022)
model.boost = train(x_train,
                    y_train,
                    method = "gbm",
                    tuneGrid = expand.grid(n.trees = c(2000, 3000, 4000, 5000),
                                           interaction.depth = 1:6,
                                           shrinkage = c(0.0005, 0.001, 0.002),
                                           n.minobsinnode = 1),
                    distribution = "adaboost",
                    metric = "ROC",
                    verbose = FALSE,
                    trControl = ctrl1)

ggplot(model.boost, highlight = T) + 
  theme_bw()
```

## Fit a support vector classifier (linear kernel)
```{r message=FALSE, warning=FALSE}
set.seed(2022)
model.svml = train(x_train,
                   y_train,
                   method = "svmLinear",
                   metric = "ROC",
                   tuneGrid = data.frame(C = exp(seq(-4, 3, length = 50))),
                   trControl = ctrl1)

ggplot(model.svml, highlight = TRUE) +
  scale_x_continuous(trans = scales::log_trans(),
                     breaks = scales::log_breaks()) + 
  theme_bw()

## test auc and misclassification error rate
pred_svml_auc <- predict(model.svml, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_svml_auc)$auc[1]

pred_svml <- predict(model.svml, newdata = x_test)
pred.miserror_svml <- 1 - mean(pred_svml == y_test)
pred.miserror_svml
```

## Fit a support vector machine with a radial kernel

```{r}
set.seed(2022)
model.svmr = train(x_train,
                 y_train,
                 method = "svmRadialSigma",
                 metric = "ROC",
                 tuneGrid = expand.grid(C = exp(seq(-1, 3, length = 20)),
                                       sigma = exp(seq(-7, -3, length = 20))),
                 trControl = ctrl1)

model.svmr$bestTune
myCol<- rainbow(20)
myPar <- list(superpose.symbol = list(col = myCol),
superpose.line = list(col = myCol))
plot(model.svmr, highlight = TRUE, par.settings = myPar)

## test auc and misclassification error rate
pred_svmr_auc <- predict(model.svmr, newdata = x_test, type = "prob")[,2]
roc(y_test, pred_svmr_auc)$auc[1]

pred_svmr <- predict(model.svmr, newdata = x_test)
pred.miserror_svmr <- 1 - mean(pred_svmr == y_test)
pred.miserror_svmr
```